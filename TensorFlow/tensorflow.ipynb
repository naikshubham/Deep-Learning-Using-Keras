{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 2.4\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import constant, Variable\n",
    "from tensorflow import GradientTape, multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining data as constants\n",
    "- use constant to transform a numpy array, credit_numpy, into a tensorflow constant, credit_constant. This array contains feature columns from a dataset on credit card holders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>29239.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDUCATION  MARRIAGE  AGE  BILL_AMT1\n",
       "0          2         1   24     3913.0\n",
       "1          2         2   26     2682.0\n",
       "2          2         2   34    29239.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.read_csv('data/uci_credit_card.csv')\n",
    "credit = credit[['EDUCATION','MARRIAGE', 'AGE','BILL_AMT1']]\n",
    "credit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(30000, 4)\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy array\n",
    "credit_numpy = np.array(credit)\n",
    "print(type(credit_numpy))\n",
    "print(credit_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The datatype is: <dtype: 'float64'>\n",
      "\n",
      " The shape is: (30000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Convert the credit_numpy array into a tensorflow constant\n",
    "credit_constant = constant(credit_numpy, )\n",
    "\n",
    "# Print constant datatype\n",
    "print('\\n The datatype is:', credit_constant.dtype)\n",
    "\n",
    "# Print constant shape\n",
    "print('\\n The shape is:', credit_constant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining variables\n",
    "- Unlike a constant, a variable's value can be modified. This will be useful when we want to train a model by updating its parameters.\n",
    "-  define and print a variable. We'll then convert the variable to a numpy array, print again, and check for differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " A1:  <tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4])>\n",
      "\n",
      " B1:  [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Define the 1-dimensional variable A1\n",
    "A1 = Variable([1, 2, 3, 4])\n",
    "\n",
    "# Print the variable A1\n",
    "print('\\n A1: ', A1)\n",
    "\n",
    "# Convert A1 to a numpy array and assign it to B1\n",
    "B1 = A1.numpy()\n",
    "\n",
    "# Print B1\n",
    "print('\\n B1: ', B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing element-wise multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " C1: [1 2 3 4]\n",
      "\n",
      " C23: [[1 2 3]\n",
      " [1 6 4]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import multiply, ones_like, matmul\n",
    "\n",
    "# Define tensors A1 and A23 as constants\n",
    "A1 = constant([1, 2, 3, 4])\n",
    "A23 = constant([[1, 2, 3], [1, 6, 4]])\n",
    "\n",
    "# Define B1 and B23 to have the correct shape\n",
    "B1 = ones_like(A1)\n",
    "B23 = ones_like(A23)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "C1 = multiply(A1, B1)\n",
    "C23 = multiply(A23, B23)\n",
    "\n",
    "# Print the tensors C1 and C23\n",
    "print('\\n C1: {}'.format(C1.numpy()))\n",
    "print('\\n C23: {}'.format(C23.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with matrix multiplication\n",
    "- We will learn to train linear regression models. This process will yield a vector of parameters that can be multiplied by the input data to generate predictions.\n",
    "- use input data, features, and a target vector, bill, which are taken from a credit card dataset\n",
    "- The matrix of input data, features, contains two columns: education level and age. The target vector, bill, is the size of the credit card borrower's bill. \n",
    "- **Since we have not trained the model, we will enter a guess for the values of the parameter vector, params. We will then use `matmul()` to perform matrix multiplication of features by params to generate predictions, billpred, which we will compare with bill.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1687]\n",
      " [-3218]\n",
      " [-1933]\n",
      " [57850]]\n"
     ]
    }
   ],
   "source": [
    "# Define features, params, and bill as constants\n",
    "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
    "params = constant([[1000], [150]])\n",
    "bill = constant([[3913], [2682], [8617], [64400]])\n",
    "\n",
    "# Compute billpred using features and params\n",
    "billpred = matmul(features, params)\n",
    "\n",
    "# Compute and print the error\n",
    "error = bill - billpred\n",
    "print(error.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Understanding matrix multiplication will make things simpler when we start making predictions with linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping tensors\n",
    "- In classification models we will classify images of sign language letters using a neural network. In some cases, the network will take 1-dimensional tensors as inputs, but our data will come in the form of images, which will either be either 2- or 3-dimensional tensors, depending on whether they are grayscale or color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1086, 1536) (625, 808, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow import reshape\n",
    "\n",
    "gray_tensor = cv2.imread('C:/Users/Shubham/Pictures/0.jpg', 0)\n",
    "color_tensor = cv2.imread('C:/Users/Shubham/Pictures/1.jpg')\n",
    "print(gray_tensor.shape, color_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the grayscale image tensor into a vector\n",
    "gray_vector = reshape(gray_tensor, (1668096, 1))\n",
    "\n",
    "# Reshape the color image tensor into a vector\n",
    "color_vector = reshape(color_tensor, (1515000, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing with gradients\n",
    "- We are given a loss function,which we want to minimize. We can do this by computing the slope using the GradientTape() operation at different values of x. If the slope is positive, we can decrease the loss by lowering x. If it is negative, we can decrease it by increasing x. This is how gradient descent works.n practice, we will use a high level tensorflow operation to perform gradient descent automatically.\n",
    "- compute the slope at x values of -1, 1, and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n",
      "2.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(x0):\n",
    "    # Define x as a variable with an initial value of x0\n",
    "    x = Variable(x0)\n",
    "    with GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "        y = multiply(x, x)\n",
    "    # Return the gradient of y with respect to x\n",
    "    return tape.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice that the slope is positive at x = 1, which means that we can lower the loss by reducing x. The slope is negative at x = -1, which means that we can lower the loss by increasing x. The slope at x = 0 is 0, which means that we cannot lower the loss by either increasing or decreasing x. This is because the loss is minimized at x = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data using pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    221900.0\n",
      "1    538000.0\n",
      "2    180000.0\n",
      "3    604000.0\n",
      "4    510000.0\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import pandas under the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the path to a string variable named data_path\n",
    "data_path = 'data/kc_house_data.csv'\n",
    "\n",
    "# Load the dataset as a dataframe named housing\n",
    "housing = pd.read_csv(data_path)\n",
    "\n",
    "# Print the price column of housing\n",
    "print(housing['price'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### price yielded a numpy array; whereas printing waterfront yielded a tf.Tensor()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean squared error (mse)\n",
    "loss = tf.keras.losses.mse(price, price)\n",
    "\n",
    "# Print the mean squared error (mse)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  MAE was much smaller than the MSE, even though price and predictions were the same. This is because the different loss functions penalize deviations of predictions from price differently. MSE does not like large deviations and punishes them harshly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the loss function\n",
    "- compute the loss within another function called `loss_function()`, which first generates predicted values from the data and variables. The purpose of this is to construct a function of the trainable model variables that returns the loss.\n",
    "- We can then repeatedly evaluate this function for different variable values until we find the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = Variable(1.0, dtype=tf.float32)\n",
    "features = np.arange(5,10)\n",
    "targets = np.arange(5)\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features = features):\n",
    "    return scalar * features\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features = features, targets = targets):\n",
    "    # Compute the predicted values\n",
    "    predictions = model(scalar, features)\n",
    "    \n",
    "    # Return the mean absolute error loss\n",
    "    return tf.keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this was the equivalent of evaluating the loss function for a linear regression where the intercept is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a linear regression\n",
    "- A univariate linear regression identifies the relationship between a single feature and the target tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613,)\n",
      "(21613,)\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.001> <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.0>\n"
     ]
    }
   ],
   "source": [
    "data = 'data/kc_house_data.csv'\n",
    "data_pd = pd.read_csv(data)\n",
    "size_log = np.log(data_pd['sqft_living'].to_numpy())\n",
    "print(size_arr.shape)\n",
    "price_log = np.log(data_pd['price'].to_numpy())\n",
    "print(price_arr.shape)\n",
    "\n",
    "slope = Variable(0.001, dtype=tf.float32)\n",
    "intercept = Variable(5.0, dtype=tf.float32)\n",
    "print(slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.9129569453266\n",
      "84.30899941394759\n"
     ]
    }
   ],
   "source": [
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features = size_log):\n",
    "    return intercept + slope * features\n",
    "\n",
    "# Set loss_function() to take the variables as arguments\n",
    "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
    "    # Set the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    "    # Return the mean squared error loss\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "\n",
    "# Compute the loss for different slope and intercept values\n",
    "print(loss_function(0.1, 0.1).numpy())\n",
    "print(loss_function(0.1, 0.5).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"def plot_results(intercept, slope):\\n\\tsize_range = np.linspace(6,14,100)\\n\\tprice_pred = [intercept+slope*s for s in size_range]\\n\\tplt.scatter(size_log, price_log, color = 'black')\\n\\tplt.plot(size_range, price_pred, linewidth=3.0, color='red')\\n\\tplt.xlabel('log(size)')\\n\\tplt.ylabel('log(price)')\\n\\tplt.title('Scatterplot of data and fitted regression line')\\n\\tplt.show()\\n\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(intercept, slope):\n",
    "    size_range = np.linspace(6,14,100)\n",
    "    price_pred = [intercept+slope*s for s in size_range]\n",
    "    plt.scatter(size_log, price_log, color = 'black')\n",
    "    plt.plot(size_range, price_pred, linewidth=3.0, color='red')\n",
    "    plt.xlabel('log(size)')\n",
    "    plt.ylabel('log(price)')\n",
    "    plt.title('Scatterplot of data and fitted regression line')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a linear model\n",
    "- define an optimization operation as opt. We will then train a univariate linear model by minimizing the loss to find the optimal values of intercept and slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.347352\n",
      "8.226627\n",
      "3.5242996\n",
      "0.22026886\n",
      "0.52341217\n",
      "0.22848657\n",
      "0.20263977\n",
      "0.15438245\n",
      "0.16139136\n",
      "0.15495746\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an adam optimizer\n",
    "opt = tf.keras.optimizers.Adam(0.5)\n",
    "\n",
    "# Apply the .minimize() method to the optimizer\n",
    "for j in range(100):\n",
    "    # Apply minimize, pass the loss function, and supply the variables\n",
    "    opt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "\n",
    "    # Print every 10th value of the loss\n",
    "    if j % 10 == 0:\n",
    "        print(loss_function(intercept, slope).numpy())\n",
    "\n",
    "# Plot data and regression line\n",
    "plot_results(intercept, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple linear regression\n",
    "- In most cases, performing a univariate linear regression will not yield a model that is useful for making accurate predictions.\n",
    "- We will use price_log as our target and size_log and bedrooms as our features.\n",
    "- We will also switch from using the the mean squared error loss to the mean absolute error loss: `keras.losses.mae()`. Finally, the predicted values are computed as follows: `params[0] + feature1*params[1] + feature2*params[2]`\n",
    "- Here, params[0] is the intercept and params[1] and params[2] are the slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0.1 , 0.05, 0.02], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "params = Variable([0.1 , 0.05, 0.02], dtype=tf.float32)\n",
    "print(params)\n",
    "\n",
    "bedrooms = data_pd['bedrooms'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 12.479, intercept: 0.102, slope_1: 0.052, slope_2: 0.022\n",
      "loss: 12.467, intercept: 0.103, slope_1: 0.053, slope_2: 0.023\n",
      "loss: 12.455, intercept: 0.104, slope_1: 0.054, slope_2: 0.024\n",
      "loss: 12.443, intercept: 0.105, slope_1: 0.055, slope_2: 0.025\n",
      "loss: 12.431, intercept: 0.106, slope_1: 0.056, slope_2: 0.026\n",
      "loss: 12.419, intercept: 0.107, slope_1: 0.057, slope_2: 0.027\n",
      "loss: 12.408, intercept: 0.108, slope_1: 0.058, slope_2: 0.028\n",
      "loss: 12.396, intercept: 0.109, slope_1: 0.059, slope_2: 0.029\n",
      "loss: 12.384, intercept: 0.110, slope_1: 0.060, slope_2: 0.030\n",
      "loss: 12.372, intercept: 0.111, slope_1: 0.061, slope_2: 0.031\n"
     ]
    }
   ],
   "source": [
    "def print_results(params):\n",
    "    return print('loss: {:0.3f}, intercept: {:0.3f}, slope_1: {:0.3f}, slope_2: {:0.3f}'.format(loss_function(params).numpy(), params[0].numpy(), params[1].numpy(), params[2].numpy()))\n",
    "\n",
    "# Define the linear regression model\n",
    "def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n",
    "    return params[0] + feature1*params[1] + feature2*params[2]\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n",
    "    # Set the predicted values\n",
    "    predictions = linear_regression(params, feature1, feature2)\n",
    "\n",
    "    # Use the mean absolute error loss\n",
    "    return tf.keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Define the optimize operation\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Perform minimization and print trainable variables\n",
    "for j in range(10):\n",
    "    opt.minimize(lambda: loss_function(params), var_list=[params])\n",
    "    print_results(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note that params[2] tells us how much the price will increase in percentage terms if we add one more bedroom. We could train params[2] and the other model parameters by increasing the number of times we iterate over opt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing to batch train\n",
    "- Before we can train a linear model in batches, we must first define variables, a loss function, and an optimization operation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the intercept and slope\n",
    "intercept = Variable(10.0)\n",
    "slope = Variable(0.5, tf.float32)\n",
    "\n",
    "# Define the model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    # Define the predicted values\n",
    "    return intercept + slope * features\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    # Define the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "\n",
    "    # Define the MSE loss\n",
    "    return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice that we did not use default argument values for the `input data, features and targets`. This is because the input data has not been defined in advance. Instead, with batch training, we will load it during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we will train a linear regression model in batches\n",
    "- We will do this by stepping through the dataset in batches and updating the model's variables, intercept and slope, after each step\n",
    "- This approach will allow us to train with datasets that are otherwise too large to hold in memory\n",
    "- The trainable variables should be entered into `var_list` in the order in which they appear as loss function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.217888 0.7016\n"
     ]
    }
   ],
   "source": [
    "# Initialize adam optimizer\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('data/kc_house_data.csv', chunksize=100):\n",
    "    size_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "\n",
    "    # Extract the price values for the current batch\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "\n",
    "    # Complete the loss, fill in the variable list, and minimize\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
    "\n",
    "# Print trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The linear algebra of dense layers\n",
    "- There are two ways to define a dense layer in tensorflow. The first involves the use of low-level, linear algebraic operations. The second makes use of high-level keras operations. \n",
    "- The input layer contains 3 features -- education, marital status, and age -- which are available as `borrower_features`. The hidden layer contains 2 nodes and the output layer contains a single node.\n",
    "- For each layer, we will take the previous layer as an input, initialize a set of weights, compute the product of the inputs and weights, and then apply an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borrower_features = np.array([[ 2.,  2., 43.]], dtype=np.float32)\n",
    "borrower_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " prediction: 0.9525741338729858\n",
      "\n",
      " actual: 1\n"
     ]
    }
   ],
   "source": [
    "# From previous step\n",
    "bias1 = Variable(1.0)\n",
    "weights1 = Variable(tf.ones((3, 2)))\n",
    "product1 = tf.matmul(borrower_features, weights1)\n",
    "dense1 = tf.keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Initialize bias2 and weights2\n",
    "bias2 = Variable(1.0)\n",
    "weights2 = Variable(tf.ones((2, 1)))\n",
    "\n",
    "# Perform matrix multiplication of dense1 and weights2\n",
    "product2 = tf.matmul(dense1, weights2)\n",
    "\n",
    "# Apply activation to product2 + bias2 and print the prediction\n",
    "prediction = tf.keras.activations.sigmoid(product2 + bias2)\n",
    "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
    "print('\\n actual: 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Our model produces predicted values in the interval between 0 and 1. For the example we considered, the actual value was 1 and the predicted value was a probability between 0 and 1. This, of course, is not meaningful, since we have not yet trained our model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
